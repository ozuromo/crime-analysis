{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../GENERATED-DATA/census_crime_clustered.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NM_DISTRIT', 'CRIMES', 'V001_ENTORNO01', 'V002_ENTORNO01',\n",
       "       'V003_ENTORNO01', 'V004_ENTORNO01', 'V001_DOMICILIORENDA',\n",
       "       'V002_DOMICILIORENDA', 'V003_DOMICILIORENDA', 'V004_DOMICILIORENDA',\n",
       "       'V001_BASICO', 'V002_BASICO', 'V003_BASICO', 'V004_BASICO',\n",
       "       'V005_BASICO', 'V006_BASICO', 'V007_BASICO', 'V008_BASICO',\n",
       "       'V009_BASICO', 'V010_BASICO', 'V011_BASICO', 'V012_BASICO',\n",
       "       'V001_DOMICILIO02', 'V002_DOMICILIO02', 'V001_DOMICILIO01',\n",
       "       'V002_DOMICILIO01', 'V001_PESSOA01', 'V086_PESSOA02', 'V001_PESSOA03',\n",
       "       'V002_PESSOA03', 'V003_PESSOA03', 'V004_PESSOA03', 'V005_PESSOA03',\n",
       "       'V006_PESSOA03', 'V001_PESSOA12', 'V001_PESSOA11', 'V001_RESPONSAVEL01',\n",
       "       'V001_RESPONSAVEL02', 'cluster', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classification Problem Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95    82.0\n",
       "Name: CRIMES, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf['CRIMES'].quantile([0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anything above the 95th quantile is going to be considered a hotspot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_target(y):\n",
    "    # bins = y.quantile([0.25, 0.5, 0.75])\n",
    "    bins = y.quantile([0.95])\n",
    "    return y.apply(lambda x: sum(x > bins))\n",
    "\n",
    "y = bin_target(gdf['CRIMES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIMES\n",
       "0    17274\n",
       "1      908\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['hotspot'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V001_ENTORNO01', 'V002_ENTORNO01', 'V003_ENTORNO01', 'V004_ENTORNO01',\n",
       "       'V001_DOMICILIORENDA', 'V002_DOMICILIORENDA', 'V003_DOMICILIORENDA',\n",
       "       'V004_DOMICILIORENDA', 'V001_BASICO', 'V002_BASICO', 'V003_BASICO',\n",
       "       'V004_BASICO', 'V005_BASICO', 'V006_BASICO', 'V007_BASICO',\n",
       "       'V008_BASICO', 'V009_BASICO', 'V010_BASICO', 'V011_BASICO',\n",
       "       'V012_BASICO', 'V001_DOMICILIO02', 'V002_DOMICILIO02',\n",
       "       'V001_DOMICILIO01', 'V002_DOMICILIO01', 'V001_PESSOA01',\n",
       "       'V086_PESSOA02', 'V001_PESSOA03', 'V002_PESSOA03', 'V003_PESSOA03',\n",
       "       'V004_PESSOA03', 'V005_PESSOA03', 'V006_PESSOA03', 'V001_PESSOA12',\n",
       "       'V001_PESSOA11', 'V001_RESPONSAVEL01', 'V001_RESPONSAVEL02', 'cluster',\n",
       "       'hotspot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gdf.drop(columns=['geometry', 'CRIMES', 'NM_DISTRIT'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def balance_classes(X, y):\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=0)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def predict_func(X_train, X_test, y_train, y_test):\n",
    "    X_train, y_train = balance_classes(X_train, y_train)\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        scale_pos_weight=1,  # Adjust based on the imbalance ratio\n",
    "        eval_metric='aucpr',\n",
    "        objective='binary:logistic',\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    result = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split train and test data\n",
    "# based on the cluster column\n",
    "def split_train_test(df, cv_column, k):\n",
    "    train = df[df[cv_column] != k]\n",
    "    test = df[df[cv_column] == k]\n",
    "    return train, test\n",
    "\n",
    "def cross_validate(df, target, cv_column, predict_func):\n",
    "    results = []\n",
    "\n",
    "    for k in df[cv_column].unique():\n",
    "        train, test = split_train_test(df, cv_column, k)\n",
    "\n",
    "        X_train = train.drop(columns=[target, cv_column])\n",
    "        X_test = test.drop(columns=[target, cv_column])\n",
    "        y_train = train[target]\n",
    "        y_test = test[target]\n",
    "\n",
    "        result = predict_func(X_train, X_test, y_train, y_test)\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "results = cross_validate(df, 'hotspot', 'cluster', predict_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster [0] - Class 1 - precision: 0.09, recall: 0.13\n",
      "Cluster [1] - Class 1 - precision: 0.12, recall: 0.08\n",
      "Cluster [2] - Class 1 - precision: 0.23, recall: 0.10\n",
      "Cluster [3] - Class 1 - precision: 0.00, recall: 0.00\n",
      "Cluster [4] - Class 1 - precision: 0.55, recall: 0.16\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f'Cluster [{i}] - Class 1 - precision: {result['1']['precision']:.2f}, recall: {result['1']['recall']:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "              precision    recall  f1-score      support\n",
      "0              0.963377  0.947872  0.955562  11184.00000\n",
      "1              0.094720  0.131466  0.110108    464.00000\n",
      "accuracy       0.915350  0.915350  0.915350      0.91535\n",
      "macro avg      0.529049  0.539669  0.532835  11648.00000\n",
      "weighted avg   0.928774  0.915350  0.921883  11648.00000\n",
      "\n",
      "Cluster 1\n",
      "              precision    recall  f1-score      support\n",
      "0              0.950960  0.970504  0.960633  5255.000000\n",
      "1              0.124294  0.077193  0.095238   285.000000\n",
      "accuracy       0.924549  0.924549  0.924549     0.924549\n",
      "macro avg      0.537627  0.523849  0.527935  5540.000000\n",
      "weighted avg   0.908433  0.924549  0.916113  5540.000000\n",
      "\n",
      "Cluster 2\n",
      "              precision    recall  f1-score     support\n",
      "0              0.835031  0.929705  0.879828  441.000000\n",
      "1              0.225000  0.100000  0.138462   90.000000\n",
      "accuracy       0.789077  0.789077  0.789077    0.789077\n",
      "macro avg      0.530015  0.514853  0.509145  531.000000\n",
      "weighted avg   0.731636  0.789077  0.754173  531.000000\n",
      "\n",
      "Cluster 3\n",
      "              precision    recall  f1-score     support\n",
      "0              0.996479  0.996479  0.996479  284.000000\n",
      "1              0.000000  0.000000  0.000000    1.000000\n",
      "accuracy       0.992982  0.992982  0.992982    0.992982\n",
      "macro avg      0.498239  0.498239  0.498239  285.000000\n",
      "weighted avg   0.992982  0.992982  0.992982  285.000000\n",
      "\n",
      "Cluster 4\n",
      "              precision    recall  f1-score     support\n",
      "0              0.639241  0.918182  0.753731  110.000000\n",
      "1              0.550000  0.161765  0.250000   68.000000\n",
      "accuracy       0.629213  0.629213  0.629213    0.629213\n",
      "macro avg      0.594620  0.539973  0.501866  178.000000\n",
      "weighted avg   0.605149  0.629213  0.561295  178.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print('Cluster', i)\n",
    "    print(pd.DataFrame(result).T)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing With no Clustered CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['hotspot', 'cluster'])\n",
    "y = df['hotspot']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotspot\n",
       "0    3464\n",
       "1     173\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotspot\n",
       "0    13810\n",
       "1    13810\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = balance_classes(X_train, y_train)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      3464\n",
      "           1       0.16      0.13      0.14       173\n",
      "\n",
      "    accuracy                           0.93      3637\n",
      "   macro avg       0.56      0.55      0.55      3637\n",
      "weighted avg       0.92      0.93      0.92      3637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=1,  # Adjust based on the imbalance ratio\n",
    "    eval_metric='aucpr',\n",
    "    objective='binary:logistic',\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with CV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = balance_classes(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91465607, 0.92377169, 0.91551763, 0.91199051, 0.90922982])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=1,  # Adjust based on the imbalance ratio\n",
    "    eval_metric='aucpr',\n",
    "    objective='binary:logistic',\n",
    ")\n",
    "\n",
    "cross_val_score(xgb, X, y, cv=5, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
